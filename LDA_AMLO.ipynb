{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddaaa301-5116-4502-8cb2-b245a939c0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 14:08:46,664 : INFO : adding document #0 to Dictionary<0 unique tokens: []>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Archivos leídos: 1337\n",
      "✓ Documentos con tokens: 1337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 14:09:05,242 : INFO : built Dictionary<77171 unique tokens: ['abandonado', 'abogado', 'aborda', 'abordar', 'abrir']...> from 1337 documents (total 7455166 corpus positions)\n",
      "2025-04-30 14:09:05,245 : INFO : Dictionary lifecycle event {'msg': \"built Dictionary<77171 unique tokens: ['abandonado', 'abogado', 'aborda', 'abordar', 'abrir']...> from 1337 documents (total 7455166 corpus positions)\", 'datetime': '2025-04-30T14:09:05.245375', 'gensim': '4.3.3', 'python': '3.12.8 (tags/v3.12.8:2dc476b, Dec  3 2024, 19:30:04) [MSC v.1942 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'created'}\n",
      "2025-04-30 14:09:05,437 : INFO : discarding 53386 tokens: [('abrir', 1039), ('acabar', 1217), ('acaparada', 1), ('acción', 1172), ('aceptar', 976), ('aclarar', 873), ('acompañar', 776), ('acordar', 936), ('acto', 971), ('actualmente', 696)]...\n",
      "2025-04-30 14:09:05,440 : INFO : keeping 23785 tokens which were in no less than 5 and no more than 668 (=50.0%) documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Términos únicos antes de filtrar: 77171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 14:09:05,635 : INFO : resulting dictionary: Dictionary<23785 unique tokens: ['abandonado', 'abogado', 'aborda', 'abordar', 'abusar']...>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Términos únicos después de filtrar: 23785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 14:09:24,568 : INFO : using symmetric alpha at 0.1\n",
      "2025-04-30 14:09:24,583 : INFO : using serial LDA version on this node\n",
      "2025-04-30 14:09:24,651 : INFO : running online LDA training, 10 topics, 10 passes over the supplied corpus of 1337 documents, updating every 8000 documents, evaluating every ~1337 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2025-04-30 14:09:24,664 : INFO : training LDA model using 4 processes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Corpus BOW contiene 1337 documentos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 14:10:01,967 : INFO : PROGRESS: pass 0, dispatched chunk #0 = documents up to #1337/1337, outstanding queue size 1\n",
      "2025-04-30 14:10:33,846 : INFO : topic #4 (0.100): 0.002*\"centavo\" + 0.002*\"medicamento\" + 0.002*\"vacuna\" + 0.002*\"homicidio\" + 0.001*\"litro\" + 0.001*\"arma\" + 0.001*\"tramo\" + 0.001*\"aéreo\" + 0.001*\"ministro\" + 0.001*\"enfermedad\"\n",
      "2025-04-30 14:10:33,849 : INFO : topic #5 (0.100): 0.002*\"vacuna\" + 0.002*\"centavo\" + 0.002*\"medicamento\" + 0.001*\"litro\" + 0.001*\"refinería\" + 0.001*\"consulta\" + 0.001*\"tramo\" + 0.001*\"crédito\" + 0.001*\"margen\" + 0.001*\"avión\"\n",
      "2025-04-30 14:10:33,853 : INFO : topic #2 (0.100): 0.003*\"centavo\" + 0.002*\"vacuna\" + 0.002*\"homicidio\" + 0.002*\"electricidad\" + 0.002*\"medicamento\" + 0.002*\"litro\" + 0.002*\"tramo\" + 0.001*\"avión\" + 0.001*\"ministro\" + 0.001*\"robo\"\n",
      "2025-04-30 14:10:33,857 : INFO : topic #1 (0.100): 0.003*\"centavo\" + 0.002*\"homicidio\" + 0.002*\"vacuna\" + 0.002*\"litro\" + 0.002*\"arma\" + 0.001*\"robo\" + 0.001*\"tramo\" + 0.001*\"medicamento\" + 0.001*\"deuda\" + 0.001*\"ministro\"\n",
      "2025-04-30 14:10:33,865 : INFO : topic #6 (0.100): 0.003*\"centavo\" + 0.003*\"vacuna\" + 0.002*\"vacunación\" + 0.002*\"tramo\" + 0.002*\"homicidio\" + 0.001*\"ministro\" + 0.001*\"dosis\" + 0.001*\"medicamento\" + 0.001*\"crédito\" + 0.001*\"robo\"\n",
      "2025-04-30 14:10:33,942 : INFO : topic diff=1.700809, rho=1.000000\n",
      "2025-04-30 14:11:16,967 : INFO : -9.037 per-word bound, 525.3 perplexity estimate based on a held-out corpus of 1337 documents with 2236943 words\n",
      "2025-04-30 14:11:16,972 : INFO : PROGRESS: pass 1, dispatched chunk #0 = documents up to #1337/1337, outstanding queue size 1\n",
      "2025-04-30 14:11:52,557 : INFO : topic #9 (0.100): 0.002*\"centavo\" + 0.002*\"robo\" + 0.002*\"crédito\" + 0.002*\"litro\" + 0.002*\"vacuna\" + 0.002*\"vivienda\" + 0.001*\"universidad\" + 0.001*\"deuda\" + 0.001*\"tramo\" + 0.001*\"medicamento\"\n",
      "2025-04-30 14:11:52,561 : INFO : topic #3 (0.100): 0.007*\"vacuna\" + 0.003*\"vacunación\" + 0.002*\"dosis\" + 0.002*\"centavo\" + 0.002*\"vacunar\" + 0.001*\"litro\" + 0.001*\"homicidio\" + 0.001*\"falso\" + 0.001*\"educativo\" + 0.001*\"medicamento\"\n",
      "2025-04-30 14:11:52,564 : INFO : topic #7 (0.100): 0.009*\"centavo\" + 0.004*\"litro\" + 0.004*\"tramo\" + 0.002*\"estación\" + 0.002*\"margen\" + 0.002*\"cancún\" + 0.002*\"homicidio\" + 0.002*\"yucatán\" + 0.002*\"consumidor\" + 0.002*\"arqueológico\"\n",
      "2025-04-30 14:11:52,569 : INFO : topic #2 (0.100): 0.002*\"homicidio\" + 0.002*\"centavo\" + 0.002*\"electricidad\" + 0.002*\"ministro\" + 0.001*\"avión\" + 0.001*\"medicamento\" + 0.001*\"mentira\" + 0.001*\"arma\" + 0.001*\"robo\" + 0.001*\"vacuna\"\n",
      "2025-04-30 14:11:52,575 : INFO : topic #4 (0.100): 0.003*\"medicamento\" + 0.002*\"homicidio\" + 0.002*\"enfermedad\" + 0.002*\"vacuna\" + 0.002*\"centavo\" + 0.001*\"crédito\" + 0.001*\"arma\" + 0.001*\"ministro\" + 0.001*\"niña\" + 0.001*\"aéreo\"\n",
      "2025-04-30 14:11:52,581 : INFO : topic diff=0.271693, rho=0.612162\n",
      "2025-04-30 14:12:41,683 : INFO : -8.945 per-word bound, 492.9 perplexity estimate based on a held-out corpus of 1337 documents with 2236943 words\n",
      "2025-04-30 14:12:41,687 : INFO : PROGRESS: pass 2, dispatched chunk #0 = documents up to #1337/1337, outstanding queue size 1\n",
      "2025-04-30 14:13:06,271 : INFO : topic #5 (0.100): 0.002*\"consulta\" + 0.002*\"refinería\" + 0.002*\"avión\" + 0.001*\"natural\" + 0.001*\"medicamento\" + 0.001*\"deuda\" + 0.001*\"energético\" + 0.001*\"hectárea\" + 0.001*\"educativo\" + 0.001*\"crédito\"\n",
      "2025-04-30 14:13:06,276 : INFO : topic #6 (0.100): 0.005*\"vacuna\" + 0.004*\"acapulco\" + 0.004*\"vacunación\" + 0.003*\"reducción\" + 0.002*\"dosis\" + 0.002*\"cama\" + 0.002*\"ocupación\" + 0.002*\"tendencia\" + 0.002*\"hospitalización\" + 0.002*\"hospitalario\"\n",
      "2025-04-30 14:13:06,279 : INFO : topic #9 (0.100): 0.003*\"crédito\" + 0.002*\"vivienda\" + 0.002*\"robo\" + 0.002*\"universidad\" + 0.002*\"deuda\" + 0.001*\"centavo\" + 0.001*\"electricidad\" + 0.001*\"litro\" + 0.001*\"consumo\" + 0.001*\"central\"\n",
      "2025-04-30 14:13:06,282 : INFO : topic #2 (0.100): 0.003*\"homicidio\" + 0.002*\"ministro\" + 0.002*\"mentira\" + 0.002*\"arma\" + 0.002*\"falso\" + 0.002*\"detenido\" + 0.001*\"ine\" + 0.001*\"droga\" + 0.001*\"electricidad\" + 0.001*\"tribunal\"\n",
      "2025-04-30 14:13:06,286 : INFO : topic #7 (0.100): 0.011*\"centavo\" + 0.005*\"litro\" + 0.005*\"tramo\" + 0.003*\"margen\" + 0.003*\"estación\" + 0.002*\"cancún\" + 0.002*\"yucatán\" + 0.002*\"consumidor\" + 0.002*\"arqueológico\" + 0.002*\"kilómetro\"\n",
      "2025-04-30 14:13:06,292 : INFO : topic diff=0.419838, rho=0.522102\n",
      "2025-04-30 14:14:05,018 : INFO : -8.862 per-word bound, 465.4 perplexity estimate based on a held-out corpus of 1337 documents with 2236943 words\n",
      "2025-04-30 14:14:05,022 : INFO : PROGRESS: pass 3, dispatched chunk #0 = documents up to #1337/1337, outstanding queue size 1\n",
      "2025-04-30 14:14:43,272 : INFO : topic #9 (0.100): 0.004*\"crédito\" + 0.003*\"vivienda\" + 0.002*\"universidad\" + 0.002*\"deuda\" + 0.002*\"electricidad\" + 0.001*\"robo\" + 0.001*\"sindicato\" + 0.001*\"central\" + 0.001*\"productor\" + 0.001*\"educativo\"\n",
      "2025-04-30 14:14:43,278 : INFO : topic #5 (0.100): 0.002*\"consulta\" + 0.002*\"avión\" + 0.002*\"refinería\" + 0.001*\"natural\" + 0.001*\"educativo\" + 0.001*\"electricidad\" + 0.001*\"energético\" + 0.001*\"deuda\" + 0.001*\"hectárea\" + 0.001*\"beca\"\n",
      "2025-04-30 14:14:43,282 : INFO : topic #4 (0.100): 0.005*\"medicamento\" + 0.003*\"enfermedad\" + 0.002*\"niña\" + 0.002*\"medicina\" + 0.002*\"epidemia\" + 0.001*\"crédito\" + 0.001*\"consulta\" + 0.001*\"clínica\" + 0.001*\"búsqueda\" + 0.001*\"coronavirus\"\n",
      "2025-04-30 14:14:43,287 : INFO : topic #1 (0.100): 0.003*\"robo\" + 0.003*\"ducto\" + 0.002*\"homicidio\" + 0.002*\"deuda\" + 0.002*\"arma\" + 0.002*\"barril\" + 0.002*\"refinería\" + 0.002*\"electricidad\" + 0.002*\"búsqueda\" + 0.002*\"toma\"\n",
      "2025-04-30 14:14:43,298 : INFO : topic #3 (0.100): 0.014*\"vacuna\" + 0.006*\"vacunación\" + 0.005*\"dosis\" + 0.003*\"vacunar\" + 0.002*\"ruta\" + 0.002*\"educativo\" + 0.002*\"maestra\" + 0.001*\"argentina\" + 0.001*\"fase\" + 0.001*\"distribuir\"\n",
      "2025-04-30 14:14:43,303 : INFO : topic diff=0.444149, rho=0.462819\n",
      "2025-04-30 14:15:31,522 : INFO : -8.815 per-word bound, 450.4 perplexity estimate based on a held-out corpus of 1337 documents with 2236943 words\n",
      "2025-04-30 14:15:31,532 : INFO : PROGRESS: pass 4, dispatched chunk #0 = documents up to #1337/1337, outstanding queue size 1\n",
      "2025-04-30 14:16:08,004 : INFO : topic #8 (0.100): 0.009*\"medicamento\" + 0.004*\"avión\" + 0.003*\"medicina\" + 0.003*\"migrant\" + 0.003*\"vacuna\" + 0.002*\"centavo\" + 0.002*\"migratorio\" + 0.002*\"litro\" + 0.002*\"ingeniero\" + 0.002*\"gratuito\"\n",
      "2025-04-30 14:16:08,010 : INFO : topic #6 (0.100): 0.007*\"acapulco\" + 0.005*\"vacuna\" + 0.004*\"reducción\" + 0.003*\"cama\" + 0.003*\"hospitalización\" + 0.003*\"epidemia\" + 0.003*\"ocupación\" + 0.003*\"vacunación\" + 0.003*\"semáforo\" + 0.003*\"hospitalario\"\n",
      "2025-04-30 14:16:08,016 : INFO : topic #5 (0.100): 0.002*\"consulta\" + 0.002*\"avión\" + 0.002*\"refinería\" + 0.002*\"natural\" + 0.001*\"electricidad\" + 0.001*\"concesión\" + 0.001*\"beca\" + 0.001*\"educativo\" + 0.001*\"energético\" + 0.001*\"deuda\"\n",
      "2025-04-30 14:16:08,019 : INFO : topic #7 (0.100): 0.013*\"centavo\" + 0.006*\"litro\" + 0.006*\"tramo\" + 0.004*\"margen\" + 0.004*\"estación\" + 0.003*\"consumidor\" + 0.003*\"arqueológico\" + 0.003*\"yucatán\" + 0.002*\"cancún\" + 0.002*\"franquicia\"\n",
      "2025-04-30 14:16:08,026 : INFO : topic #1 (0.100): 0.004*\"robo\" + 0.003*\"ducto\" + 0.002*\"barril\" + 0.002*\"arma\" + 0.002*\"homicidio\" + 0.002*\"deuda\" + 0.002*\"refinería\" + 0.002*\"electricidad\" + 0.002*\"toma\" + 0.002*\"tratado\"\n",
      "2025-04-30 14:16:08,033 : INFO : topic diff=0.432101, rho=0.420016\n",
      "2025-04-30 14:16:47,806 : INFO : -8.787 per-word bound, 441.8 perplexity estimate based on a held-out corpus of 1337 documents with 2236943 words\n",
      "2025-04-30 14:16:47,812 : INFO : PROGRESS: pass 5, dispatched chunk #0 = documents up to #1337/1337, outstanding queue size 1\n",
      "2025-04-30 14:17:15,283 : INFO : topic #3 (0.100): 0.021*\"vacuna\" + 0.009*\"vacunación\" + 0.007*\"dosis\" + 0.005*\"vacunar\" + 0.003*\"ruta\" + 0.002*\"educativo\" + 0.002*\"maestra\" + 0.002*\"argentina\" + 0.002*\"fase\" + 0.002*\"distribuir\"\n",
      "2025-04-30 14:17:15,289 : INFO : topic #8 (0.100): 0.010*\"medicamento\" + 0.005*\"avión\" + 0.003*\"migrant\" + 0.003*\"medicina\" + 0.002*\"vacuna\" + 0.002*\"migratorio\" + 0.002*\"ingeniero\" + 0.002*\"gratuito\" + 0.002*\"abasto\" + 0.002*\"paciente\"\n",
      "2025-04-30 14:17:15,293 : INFO : topic #2 (0.100): 0.003*\"homicidio\" + 0.003*\"mentira\" + 0.002*\"ministro\" + 0.002*\"arma\" + 0.002*\"detenido\" + 0.002*\"falso\" + 0.002*\"droga\" + 0.002*\"ine\" + 0.002*\"detención\" + 0.002*\"tribunal\"\n",
      "2025-04-30 14:17:15,298 : INFO : topic #6 (0.100): 0.008*\"acapulco\" + 0.005*\"vacuna\" + 0.004*\"reducción\" + 0.004*\"epidemia\" + 0.004*\"cama\" + 0.004*\"hospitalización\" + 0.004*\"ocupación\" + 0.004*\"semáforo\" + 0.003*\"hospitalario\" + 0.003*\"curva\"\n",
      "2025-04-30 14:17:15,304 : INFO : topic #5 (0.100): 0.002*\"consulta\" + 0.002*\"avión\" + 0.002*\"refinería\" + 0.002*\"natural\" + 0.001*\"concesión\" + 0.001*\"electricidad\" + 0.001*\"beca\" + 0.001*\"educativo\" + 0.001*\"deuda\" + 0.001*\"energético\"\n",
      "2025-04-30 14:17:15,309 : INFO : topic diff=0.404094, rho=0.387245\n",
      "2025-04-30 14:17:54,679 : INFO : -8.770 per-word bound, 436.6 perplexity estimate based on a held-out corpus of 1337 documents with 2236943 words\n",
      "2025-04-30 14:17:54,684 : INFO : PROGRESS: pass 6, dispatched chunk #0 = documents up to #1337/1337, outstanding queue size 1\n",
      "2025-04-30 14:18:21,848 : INFO : topic #1 (0.100): 0.004*\"robo\" + 0.003*\"ducto\" + 0.003*\"barril\" + 0.002*\"arma\" + 0.002*\"refinería\" + 0.002*\"homicidio\" + 0.002*\"deuda\" + 0.002*\"toma\" + 0.002*\"tratado\" + 0.002*\"víctima\"\n",
      "2025-04-30 14:18:21,854 : INFO : topic #7 (0.100): 0.015*\"centavo\" + 0.007*\"litro\" + 0.006*\"tramo\" + 0.005*\"margen\" + 0.004*\"estación\" + 0.003*\"consumidor\" + 0.003*\"arqueológico\" + 0.003*\"yucatán\" + 0.003*\"franquicia\" + 0.003*\"cancún\"\n",
      "2025-04-30 14:18:21,859 : INFO : topic #8 (0.100): 0.012*\"medicamento\" + 0.006*\"avión\" + 0.004*\"migrant\" + 0.004*\"medicina\" + 0.002*\"vacuna\" + 0.002*\"migratorio\" + 0.002*\"gratuito\" + 0.002*\"ingeniero\" + 0.002*\"abasto\" + 0.002*\"migración\"\n",
      "2025-04-30 14:18:21,862 : INFO : topic #5 (0.100): 0.002*\"consulta\" + 0.002*\"avión\" + 0.002*\"refinería\" + 0.002*\"natural\" + 0.002*\"concesión\" + 0.002*\"electricidad\" + 0.001*\"beca\" + 0.001*\"falso\" + 0.001*\"deuda\" + 0.001*\"educativo\"\n",
      "2025-04-30 14:18:21,866 : INFO : topic #4 (0.100): 0.006*\"medicamento\" + 0.003*\"enfermedad\" + 0.002*\"medicina\" + 0.002*\"niña\" + 0.002*\"especialidad\" + 0.002*\"epidemia\" + 0.002*\"clínica\" + 0.002*\"coronavirus\" + 0.002*\"consulta\" + 0.002*\"abasto\"\n",
      "2025-04-30 14:18:21,873 : INFO : topic diff=0.367623, rho=0.361114\n",
      "2025-04-30 14:18:58,367 : INFO : -8.759 per-word bound, 433.3 perplexity estimate based on a held-out corpus of 1337 documents with 2236943 words\n",
      "2025-04-30 14:18:58,372 : INFO : PROGRESS: pass 7, dispatched chunk #0 = documents up to #1337/1337, outstanding queue size 1\n",
      "2025-04-30 14:19:21,958 : INFO : topic #2 (0.100): 0.003*\"homicidio\" + 0.003*\"mentira\" + 0.003*\"ministro\" + 0.002*\"arma\" + 0.002*\"detenido\" + 0.002*\"falso\" + 0.002*\"droga\" + 0.002*\"detención\" + 0.002*\"magistrado\" + 0.002*\"tribunal\"\n",
      "2025-04-30 14:19:21,960 : INFO : topic #1 (0.100): 0.004*\"robo\" + 0.004*\"ducto\" + 0.003*\"barril\" + 0.003*\"arma\" + 0.002*\"refinería\" + 0.002*\"homicidio\" + 0.002*\"deuda\" + 0.002*\"tratado\" + 0.002*\"toma\" + 0.002*\"víctima\"\n",
      "2025-04-30 14:19:21,965 : INFO : topic #5 (0.100): 0.002*\"consulta\" + 0.002*\"avión\" + 0.002*\"refinería\" + 0.002*\"concesión\" + 0.002*\"electricidad\" + 0.002*\"natural\" + 0.001*\"beca\" + 0.001*\"falso\" + 0.001*\"deuda\" + 0.001*\"universidad\"\n",
      "2025-04-30 14:19:21,970 : INFO : topic #7 (0.100): 0.015*\"centavo\" + 0.007*\"litro\" + 0.007*\"tramo\" + 0.005*\"margen\" + 0.004*\"estación\" + 0.003*\"arqueológico\" + 0.003*\"consumidor\" + 0.003*\"yucatán\" + 0.003*\"franquicia\" + 0.003*\"cancún\"\n",
      "2025-04-30 14:19:21,976 : INFO : topic #9 (0.100): 0.007*\"crédito\" + 0.004*\"vivienda\" + 0.003*\"productor\" + 0.003*\"electricidad\" + 0.003*\"sindicato\" + 0.002*\"universidad\" + 0.002*\"deuda\" + 0.002*\"central\" + 0.002*\"infonavit\" + 0.002*\"educativo\"\n",
      "2025-04-30 14:19:21,980 : INFO : topic diff=0.328161, rho=0.339647\n",
      "2025-04-30 14:19:57,401 : INFO : -8.752 per-word bound, 431.3 perplexity estimate based on a held-out corpus of 1337 documents with 2236943 words\n",
      "2025-04-30 14:19:57,405 : INFO : PROGRESS: pass 8, dispatched chunk #0 = documents up to #1337/1337, outstanding queue size 1\n",
      "2025-04-30 14:20:23,509 : INFO : topic #5 (0.100): 0.002*\"consulta\" + 0.002*\"avión\" + 0.002*\"refinería\" + 0.002*\"concesión\" + 0.002*\"electricidad\" + 0.002*\"natural\" + 0.001*\"beca\" + 0.001*\"falso\" + 0.001*\"deuda\" + 0.001*\"universidad\"\n",
      "2025-04-30 14:20:23,513 : INFO : topic #4 (0.100): 0.007*\"medicamento\" + 0.004*\"enfermedad\" + 0.003*\"medicina\" + 0.002*\"especialidad\" + 0.002*\"niña\" + 0.002*\"clínica\" + 0.002*\"epidemia\" + 0.002*\"coronavirus\" + 0.002*\"consulta\" + 0.002*\"abasto\"\n",
      "2025-04-30 14:20:23,518 : INFO : topic #3 (0.100): 0.029*\"vacuna\" + 0.012*\"vacunación\" + 0.010*\"dosis\" + 0.007*\"vacunar\" + 0.003*\"ruta\" + 0.003*\"educativo\" + 0.002*\"argentina\" + 0.002*\"maestra\" + 0.002*\"fase\" + 0.002*\"distribuir\"\n",
      "2025-04-30 14:20:23,521 : INFO : topic #2 (0.100): 0.003*\"homicidio\" + 0.003*\"ministro\" + 0.003*\"mentira\" + 0.003*\"arma\" + 0.002*\"detenido\" + 0.002*\"falso\" + 0.002*\"droga\" + 0.002*\"detención\" + 0.002*\"magistrado\" + 0.002*\"tribunal\"\n",
      "2025-04-30 14:20:23,526 : INFO : topic #7 (0.100): 0.016*\"centavo\" + 0.008*\"litro\" + 0.007*\"tramo\" + 0.005*\"margen\" + 0.004*\"estación\" + 0.003*\"arqueológico\" + 0.003*\"consumidor\" + 0.003*\"yucatán\" + 0.003*\"franquicia\" + 0.003*\"cancún\"\n",
      "2025-04-30 14:20:23,532 : INFO : topic diff=0.289575, rho=0.321603\n",
      "2025-04-30 14:20:58,884 : INFO : -8.748 per-word bound, 430.0 perplexity estimate based on a held-out corpus of 1337 documents with 2236943 words\n",
      "2025-04-30 14:20:58,888 : INFO : PROGRESS: pass 9, dispatched chunk #0 = documents up to #1337/1337, outstanding queue size 1\n",
      "2025-04-30 14:21:21,708 : INFO : topic #3 (0.100): 0.031*\"vacuna\" + 0.012*\"vacunación\" + 0.010*\"dosis\" + 0.008*\"vacunar\" + 0.003*\"ruta\" + 0.003*\"educativo\" + 0.003*\"argentina\" + 0.003*\"fase\" + 0.002*\"maestra\" + 0.002*\"canciller\"\n",
      "2025-04-30 14:21:21,711 : INFO : topic #6 (0.100): 0.010*\"acapulco\" + 0.006*\"epidemia\" + 0.005*\"reducción\" + 0.005*\"cama\" + 0.005*\"hospitalización\" + 0.004*\"semáforo\" + 0.004*\"vacuna\" + 0.004*\"ocupación\" + 0.004*\"hospitalario\" + 0.004*\"curva\"\n",
      "2025-04-30 14:21:21,714 : INFO : topic #8 (0.100): 0.014*\"medicamento\" + 0.008*\"avión\" + 0.005*\"migrant\" + 0.004*\"medicina\" + 0.003*\"migratorio\" + 0.002*\"migración\" + 0.002*\"venta\" + 0.002*\"gratuito\" + 0.002*\"ingeniero\" + 0.002*\"abasto\"\n",
      "2025-04-30 14:21:21,719 : INFO : topic #9 (0.100): 0.008*\"crédito\" + 0.004*\"vivienda\" + 0.003*\"productor\" + 0.003*\"sindicato\" + 0.003*\"electricidad\" + 0.002*\"universidad\" + 0.002*\"deuda\" + 0.002*\"central\" + 0.002*\"infonavit\" + 0.002*\"educativo\"\n",
      "2025-04-30 14:21:21,723 : INFO : topic #2 (0.100): 0.003*\"homicidio\" + 0.003*\"ministro\" + 0.003*\"mentira\" + 0.003*\"arma\" + 0.002*\"detenido\" + 0.002*\"falso\" + 0.002*\"droga\" + 0.002*\"magistrado\" + 0.002*\"detención\" + 0.002*\"tribunal\"\n",
      "2025-04-30 14:21:21,728 : INFO : topic diff=0.254072, rho=0.306160\n",
      "2025-04-30 14:21:57,687 : INFO : -8.746 per-word bound, 429.3 perplexity estimate based on a held-out corpus of 1337 documents with 2236943 words\n",
      "2025-04-30 14:21:57,795 : INFO : LdaMulticore lifecycle event {'msg': 'trained LdaMulticore<num_terms=23785, num_topics=10, decay=0.5, chunksize=2000> in 753.14s', 'datetime': '2025-04-30T14:21:57.792403', 'gensim': '4.3.3', 'python': '3.12.8 (tags/v3.12.8:2dc476b, Dec  3 2024, 19:30:04) [MSC v.1942 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'created'}\n",
      "2025-04-30 14:21:57,837 : INFO : topic #0 (0.100): 0.012*\"vacuna\" + 0.005*\"homicidio\" + 0.005*\"vacunación\" + 0.005*\"dosis\" + 0.004*\"tendencia\" + 0.004*\"robo\" + 0.004*\"vacunar\" + 0.003*\"medicamento\" + 0.003*\"doloso\" + 0.003*\"aéreo\"\n",
      "2025-04-30 14:21:57,846 : INFO : topic #1 (0.100): 0.004*\"robo\" + 0.004*\"ducto\" + 0.003*\"barril\" + 0.003*\"arma\" + 0.002*\"refinería\" + 0.002*\"homicidio\" + 0.002*\"deuda\" + 0.002*\"víctima\" + 0.002*\"tratado\" + 0.002*\"toma\"\n",
      "2025-04-30 14:21:57,851 : INFO : topic #2 (0.100): 0.003*\"homicidio\" + 0.003*\"ministro\" + 0.003*\"mentira\" + 0.003*\"arma\" + 0.002*\"detenido\" + 0.002*\"falso\" + 0.002*\"droga\" + 0.002*\"magistrado\" + 0.002*\"detención\" + 0.002*\"tribunal\"\n",
      "2025-04-30 14:21:57,857 : INFO : topic #3 (0.100): 0.031*\"vacuna\" + 0.012*\"vacunación\" + 0.010*\"dosis\" + 0.008*\"vacunar\" + 0.003*\"ruta\" + 0.003*\"educativo\" + 0.003*\"argentina\" + 0.003*\"fase\" + 0.002*\"maestra\" + 0.002*\"canciller\"\n",
      "2025-04-30 14:21:57,861 : INFO : topic #4 (0.100): 0.007*\"medicamento\" + 0.004*\"enfermedad\" + 0.003*\"medicina\" + 0.003*\"especialidad\" + 0.002*\"niña\" + 0.002*\"clínica\" + 0.002*\"epidemia\" + 0.002*\"coronavirus\" + 0.002*\"consulta\" + 0.002*\"abasto\"\n",
      "2025-04-30 14:21:57,866 : INFO : topic #5 (0.100): 0.002*\"consulta\" + 0.002*\"avión\" + 0.002*\"refinería\" + 0.002*\"concesión\" + 0.002*\"electricidad\" + 0.002*\"natural\" + 0.001*\"beca\" + 0.001*\"falso\" + 0.001*\"deuda\" + 0.001*\"universidad\"\n",
      "2025-04-30 14:21:57,870 : INFO : topic #6 (0.100): 0.010*\"acapulco\" + 0.006*\"epidemia\" + 0.005*\"reducción\" + 0.005*\"cama\" + 0.005*\"hospitalización\" + 0.004*\"semáforo\" + 0.004*\"vacuna\" + 0.004*\"ocupación\" + 0.004*\"hospitalario\" + 0.004*\"curva\"\n",
      "2025-04-30 14:21:57,878 : INFO : topic #7 (0.100): 0.016*\"centavo\" + 0.008*\"litro\" + 0.007*\"tramo\" + 0.005*\"margen\" + 0.004*\"estación\" + 0.003*\"arqueológico\" + 0.003*\"consumidor\" + 0.003*\"yucatán\" + 0.003*\"franquicia\" + 0.003*\"cancún\"\n",
      "2025-04-30 14:21:57,883 : INFO : topic #8 (0.100): 0.014*\"medicamento\" + 0.008*\"avión\" + 0.005*\"migrant\" + 0.004*\"medicina\" + 0.003*\"migratorio\" + 0.002*\"migración\" + 0.002*\"venta\" + 0.002*\"gratuito\" + 0.002*\"ingeniero\" + 0.002*\"abasto\"\n",
      "2025-04-30 14:21:57,889 : INFO : topic #9 (0.100): 0.008*\"crédito\" + 0.004*\"vivienda\" + 0.003*\"productor\" + 0.003*\"sindicato\" + 0.003*\"electricidad\" + 0.002*\"universidad\" + 0.002*\"deuda\" + 0.002*\"central\" + 0.002*\"infonavit\" + 0.002*\"educativo\"\n",
      "2025-04-30 14:21:57,919 : INFO : using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tópicos extraídos ---\n",
      "Tópico  0: 0.012*\"vacuna\" + 0.005*\"homicidio\" + 0.005*\"vacunación\" + 0.005*\"dosis\" + 0.004*\"tendencia\" + 0.004*\"robo\" + 0.004*\"vacunar\" + 0.003*\"medicamento\" + 0.003*\"doloso\" + 0.003*\"aéreo\"\n",
      "Tópico  1: 0.004*\"robo\" + 0.004*\"ducto\" + 0.003*\"barril\" + 0.003*\"arma\" + 0.002*\"refinería\" + 0.002*\"homicidio\" + 0.002*\"deuda\" + 0.002*\"víctima\" + 0.002*\"tratado\" + 0.002*\"toma\"\n",
      "Tópico  2: 0.003*\"homicidio\" + 0.003*\"ministro\" + 0.003*\"mentira\" + 0.003*\"arma\" + 0.002*\"detenido\" + 0.002*\"falso\" + 0.002*\"droga\" + 0.002*\"magistrado\" + 0.002*\"detención\" + 0.002*\"tribunal\"\n",
      "Tópico  3: 0.031*\"vacuna\" + 0.012*\"vacunación\" + 0.010*\"dosis\" + 0.008*\"vacunar\" + 0.003*\"ruta\" + 0.003*\"educativo\" + 0.003*\"argentina\" + 0.003*\"fase\" + 0.002*\"maestra\" + 0.002*\"canciller\"\n",
      "Tópico  4: 0.007*\"medicamento\" + 0.004*\"enfermedad\" + 0.003*\"medicina\" + 0.003*\"especialidad\" + 0.002*\"niña\" + 0.002*\"clínica\" + 0.002*\"epidemia\" + 0.002*\"coronavirus\" + 0.002*\"consulta\" + 0.002*\"abasto\"\n",
      "Tópico  5: 0.002*\"consulta\" + 0.002*\"avión\" + 0.002*\"refinería\" + 0.002*\"concesión\" + 0.002*\"electricidad\" + 0.002*\"natural\" + 0.001*\"beca\" + 0.001*\"falso\" + 0.001*\"deuda\" + 0.001*\"universidad\"\n",
      "Tópico  6: 0.010*\"acapulco\" + 0.006*\"epidemia\" + 0.005*\"reducción\" + 0.005*\"cama\" + 0.005*\"hospitalización\" + 0.004*\"semáforo\" + 0.004*\"vacuna\" + 0.004*\"ocupación\" + 0.004*\"hospitalario\" + 0.004*\"curva\"\n",
      "Tópico  7: 0.016*\"centavo\" + 0.008*\"litro\" + 0.007*\"tramo\" + 0.005*\"margen\" + 0.004*\"estación\" + 0.003*\"arqueológico\" + 0.003*\"consumidor\" + 0.003*\"yucatán\" + 0.003*\"franquicia\" + 0.003*\"cancún\"\n",
      "Tópico  8: 0.014*\"medicamento\" + 0.008*\"avión\" + 0.005*\"migrant\" + 0.004*\"medicina\" + 0.003*\"migratorio\" + 0.002*\"migración\" + 0.002*\"venta\" + 0.002*\"gratuito\" + 0.002*\"ingeniero\" + 0.002*\"abasto\"\n",
      "Tópico  9: 0.008*\"crédito\" + 0.004*\"vivienda\" + 0.003*\"productor\" + 0.003*\"sindicato\" + 0.003*\"electricidad\" + 0.002*\"universidad\" + 0.002*\"deuda\" + 0.002*\"central\" + 0.002*\"infonavit\" + 0.002*\"educativo\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 14:22:54,774 : INFO : 1 batches submitted to accumulate stats from 64 documents (418552 virtual)\n",
      "2025-04-30 14:22:55,058 : INFO : 2 batches submitted to accumulate stats from 128 documents (841223 virtual)\n",
      "2025-04-30 14:22:55,312 : INFO : 3 batches submitted to accumulate stats from 192 documents (1248476 virtual)\n",
      "2025-04-30 14:22:55,642 : INFO : 4 batches submitted to accumulate stats from 256 documents (1635679 virtual)\n",
      "2025-04-30 14:22:56,046 : INFO : 5 batches submitted to accumulate stats from 320 documents (2035334 virtual)\n",
      "2025-04-30 14:22:56,475 : INFO : 6 batches submitted to accumulate stats from 384 documents (2451145 virtual)\n",
      "2025-04-30 14:22:56,904 : INFO : 7 batches submitted to accumulate stats from 448 documents (2829924 virtual)\n",
      "2025-04-30 14:22:57,380 : INFO : 8 batches submitted to accumulate stats from 512 documents (3198689 virtual)\n",
      "2025-04-30 14:22:57,847 : INFO : 9 batches submitted to accumulate stats from 576 documents (3545478 virtual)\n",
      "2025-04-30 14:22:58,259 : INFO : 10 batches submitted to accumulate stats from 640 documents (3882282 virtual)\n",
      "2025-04-30 14:22:58,690 : INFO : 11 batches submitted to accumulate stats from 704 documents (4206266 virtual)\n",
      "2025-04-30 14:22:59,099 : INFO : 12 batches submitted to accumulate stats from 768 documents (4540354 virtual)\n",
      "2025-04-30 14:22:59,533 : INFO : 13 batches submitted to accumulate stats from 832 documents (4889986 virtual)\n",
      "2025-04-30 14:22:59,961 : INFO : 14 batches submitted to accumulate stats from 896 documents (5238089 virtual)\n",
      "2025-04-30 14:23:26,774 : INFO : 15 batches submitted to accumulate stats from 960 documents (5584500 virtual)\n",
      "2025-04-30 14:23:27,452 : INFO : 16 batches submitted to accumulate stats from 1024 documents (5920959 virtual)\n",
      "2025-04-30 14:23:27,875 : INFO : 17 batches submitted to accumulate stats from 1088 documents (6254924 virtual)\n",
      "2025-04-30 14:23:28,301 : INFO : 18 batches submitted to accumulate stats from 1152 documents (6564090 virtual)\n",
      "2025-04-30 14:23:28,669 : INFO : 19 batches submitted to accumulate stats from 1216 documents (6870263 virtual)\n",
      "2025-04-30 14:23:30,088 : INFO : 20 batches submitted to accumulate stats from 1280 documents (7116664 virtual)\n",
      "2025-04-30 14:23:30,614 : INFO : 21 batches submitted to accumulate stats from 1344 documents (7309433 virtual)\n",
      "2025-04-30 14:24:17,033 : INFO : 7 accumulators retrieved from output queue\n",
      "2025-04-30 14:24:17,184 : INFO : accumulated word occurrence stats for 7310711 virtual documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherencia del modelo (c_v): 0.4524\n",
      "\n",
      "[✓] Visualización guardada en:\n",
      "    D:\\Transcripciones_Mañaneras_StopWords\\Results\\lda_visualization.html\n",
      "[✓] Nube Tópico 1 → D:\\Transcripciones_Mañaneras_StopWords\\Results\\wordcloud_topic_1.png\n",
      "[✓] Nube Tópico 2 → D:\\Transcripciones_Mañaneras_StopWords\\Results\\wordcloud_topic_2.png\n",
      "[✓] Nube Tópico 3 → D:\\Transcripciones_Mañaneras_StopWords\\Results\\wordcloud_topic_3.png\n",
      "[✓] Nube Tópico 4 → D:\\Transcripciones_Mañaneras_StopWords\\Results\\wordcloud_topic_4.png\n",
      "[✓] Nube Tópico 5 → D:\\Transcripciones_Mañaneras_StopWords\\Results\\wordcloud_topic_5.png\n",
      "[✓] Nube Tópico 6 → D:\\Transcripciones_Mañaneras_StopWords\\Results\\wordcloud_topic_6.png\n",
      "[✓] Nube Tópico 7 → D:\\Transcripciones_Mañaneras_StopWords\\Results\\wordcloud_topic_7.png\n",
      "[✓] Nube Tópico 8 → D:\\Transcripciones_Mañaneras_StopWords\\Results\\wordcloud_topic_8.png\n",
      "[✓] Nube Tópico 9 → D:\\Transcripciones_Mañaneras_StopWords\\Results\\wordcloud_topic_9.png\n",
      "[✓] Nube Tópico 10 → D:\\Transcripciones_Mañaneras_StopWords\\Results\\wordcloud_topic_10.png\n",
      "\n",
      "¡Proceso completado!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import LdaMulticore, CoherenceModel\n",
    "\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 0) Logging para ver el progreso de gensim en la consola\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s : %(levelname)s : %(message)s',\n",
    "    level=logging.INFO\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 1) Parámetros de usuario\n",
    "INPUT_DIR    = r\"D:\\Transcripciones_Mañaneras_StopWords\"\n",
    "OUTPUT_DIR   = r\"D:\\Transcripciones_Mañaneras_StopWords\\Results\"\n",
    "NUM_TOPICS   = 10\n",
    "PASSES       = 10\n",
    "CHUNK_SIZE   = 2000\n",
    "WORKERS      = 4    # número de hilos para LdaMulticore\n",
    "NO_BELOW     = 5    # descartar términos en < 5 documentos\n",
    "NO_ABOVE     = 0.5  # descartar términos en >50% de los documentos\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 2) Carga de documentos: cada línea/token ya está preprocesado\n",
    "documents = []\n",
    "file_count = 0\n",
    "\n",
    "for root, _, files in os.walk(INPUT_DIR):\n",
    "    for fname in files:\n",
    "        if fname.lower().endswith(\".txt\"):\n",
    "            file_count += 1\n",
    "            path = os.path.join(root, fname)\n",
    "            with open(path, encoding=\"utf-8\") as f:\n",
    "                tokens = f.read().split()\n",
    "            if tokens:\n",
    "                documents.append(tokens)\n",
    "\n",
    "if file_count == 0:\n",
    "    raise RuntimeError(f\"No se encontró ningún .txt bajo {INPUT_DIR}\")\n",
    "if not documents:\n",
    "    raise RuntimeError(f\"Ningún documento con tokens válidos en {INPUT_DIR}\")\n",
    "\n",
    "print(f\"✓ Archivos leídos: {file_count}\")\n",
    "print(f\"✓ Documentos con tokens: {len(documents)}\")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 3) Construye el diccionario y filtra extremos\n",
    "dictionary = corpora.Dictionary(documents)\n",
    "print(f\"→ Términos únicos antes de filtrar: {len(dictionary)}\")\n",
    "\n",
    "dictionary.filter_extremes(\n",
    "    no_below=NO_BELOW,\n",
    "    no_above=NO_ABOVE\n",
    ")\n",
    "print(f\"→ Términos únicos después de filtrar: {len(dictionary)}\")\n",
    "if len(dictionary) == 0:\n",
    "    raise RuntimeError(\"Diccionario vacío tras filter_extremes(). Ajusta NO_BELOW/NO_ABOVE.\")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 4) Crea el corpus bag-of-words, descartando docs vacíos\n",
    "corpus = [\n",
    "    dictionary.doc2bow(doc)\n",
    "    for doc in documents\n",
    "    if dictionary.doc2bow(doc)\n",
    "]\n",
    "print(f\"✓ Corpus BOW contiene {len(corpus)} documentos\")\n",
    "if not corpus:\n",
    "    raise RuntimeError(\"Todos los documentos quedaron vacíos tras doc2bow().\")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 5) Entrena el modelo LDA en paralelo\n",
    "lda_model = LdaMulticore(\n",
    "    corpus=corpus,\n",
    "    id2word=dictionary,\n",
    "    num_topics=NUM_TOPICS,\n",
    "    passes=PASSES,\n",
    "    chunksize=CHUNK_SIZE,\n",
    "    workers=WORKERS,\n",
    "    random_state=42,\n",
    "    eta='auto',\n",
    "    decay=0.5\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 6) Imprime temas y calcula coherencia\n",
    "print(\"\\n--- Tópicos extraídos ---\")\n",
    "for topic_id, topic in lda_model.print_topics(num_topics=NUM_TOPICS, num_words=10):\n",
    "    print(f\"Tópico {topic_id:>2}: {topic}\")\n",
    "\n",
    "coherence = CoherenceModel(\n",
    "    model=lda_model,\n",
    "    texts=documents,\n",
    "    dictionary=dictionary,\n",
    "    coherence='c_v'\n",
    ").get_coherence()\n",
    "print(f\"\\nCoherencia del modelo (c_v): {coherence:.4f}\")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 7) Guarda la visualización interactiva como HTML\n",
    "vis = gensimvis.prepare(lda_model, corpus, dictionary)\n",
    "html_path = os.path.join(OUTPUT_DIR, \"lda_visualization.html\")\n",
    "pyLDAvis.save_html(vis, html_path)\n",
    "print(f\"\\n[✓] Visualización guardada en:\\n    {html_path}\")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 8) Genera y guarda nubes de palabras por tópico\n",
    "for t in range(NUM_TOPICS):\n",
    "    freqs = dict(lda_model.show_topic(t, topn=20))\n",
    "    wc = WordCloud(\n",
    "        width=800, height=400,\n",
    "        background_color='white'\n",
    "    ).generate_from_frequencies(freqs)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Tópico {t+1}\")\n",
    "    \n",
    "    img_path = os.path.join(\n",
    "        OUTPUT_DIR,\n",
    "        f\"wordcloud_topic_{t+1}.png\"\n",
    "    )\n",
    "    plt.savefig(img_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"[✓] Nube Tópico {t+1} → {img_path}\")\n",
    "\n",
    "print(\"\\n¡Proceso completado!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1927f1-cd13-43d9-b0e4-b6e1e89fcf8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
